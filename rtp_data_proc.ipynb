{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#load in all RTP .txt files and convet to strings for manipulation\n",
    "path = \"./data/raw/RTP/\"\n",
    "filenames = os.listdir(path)\n",
    "\n",
    "with open(path + filenames[0], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP8990 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[1], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9091 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[2], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9192 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[3], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9293 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[4], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9394 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[5], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9495 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[6], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9596 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[7], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9697 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[8], \"r\", encoding=\"utf8\") as f: \n",
    "    RTP9798 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[9], \"r\", encoding=\"utf8\") as f:\n",
    "    RTP9899 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "with open(path + filenames[10],\"r\", encoding=\"utf8\") as f:\n",
    "    RTP9900 = f.read().replace(\"\\n\",\" \").replace(\"- \",\"\")\n",
    "\n",
    "corpori = [\n",
    "    RTP8990, RTP9091, RTP9192, RTP9293, RTP9394, RTP9495, RTP9596, RTP9697, RTP9798, RTP9899, RTP9900\n",
    "]\n",
    "\n",
    "#pre-processing modules + sentence tokenization\n",
    "negation_words = [\"no\", \"never\", \"neither\", \"hardly\", \"less\"]\n",
    "for corpus in corpori:\n",
    "    corpus = corpus.lower() #remove capitalization\n",
    "    for word in negation_words: #remove basic negation words\n",
    "        corpus = corpus.replace(word, \"not\")\n",
    "    corpus = sent_tokenize(corpus) #tokenize\n",
    "\n",
    "\n",
    "#column 0 will contain sentence, column 1 will contain volume years, column 2 will be prediction\n",
    "#use list.pop(0) to get rid of the instantiate row\n",
    "#fill zeros in 2nd column until we get predictions\n",
    "abortion = [[0, 0, 0]]\n",
    "welfare = [[0, 0, 0]]\n",
    "pay_gap = [[0, 0, 0]]\n",
    "bush = [[0, 0, 0]]\n",
    "clinton = [[0, 0, 0]]\n",
    "dole = [[0, 0, 0]]\n",
    "affirmative_action = [[0, 0, 0]]\n",
    "conservative = [[0, 0, 0]]\n",
    "liberal = [[0, 0, 0]]\n",
    "republican = [[0, 0, 0]]\n",
    "democrat = [[0, 0, 0]]\n",
    "gay = [[0, 0, 0]]\n",
    "\n",
    "issues = [\n",
    "    abortion, welfare, pay_gap, bush, clinton, dole, affirmative_action, conservative, liberal, republican, democrat, gay\n",
    "]\n",
    "\n",
    "current_years = \"\"\n",
    "current_index = 0\n",
    "for corpus in corpori:\n",
    "\n",
    "    current_index = corpori.index(corpus)\n",
    "    if current_index == 0:\n",
    "        current_years = \"8990\"\n",
    "    elif current_index == 1:\n",
    "        current_years = \"9091\"\n",
    "    elif current_index == 2:\n",
    "        current_years = \"9192\"\n",
    "    elif current_index == 3:\n",
    "        current_years = \"9293\"\n",
    "    elif current_index == 4:\n",
    "        current_years = \"9394\"\n",
    "    elif current_index == 5:\n",
    "        current_years = \"9495\"\n",
    "    elif current_index == 6:\n",
    "        current_years = \"9596\"\n",
    "    elif current_index == 7:\n",
    "        current_years = \"9697\"\n",
    "    elif current_index == 8:\n",
    "        current_years = \"9798\"\n",
    "    elif current_index == 9:\n",
    "        current_years = \"9899\"\n",
    "    elif current_index == 10:\n",
    "        current_years = \"9900\"\n",
    "    else:\n",
    "        raise IndexError(\"Invalid index\")\n",
    "\n",
    "    for sentence in corpus:\n",
    "        if \"abortion\" in sentence:\n",
    "            abortion.append([sentence, current_years, 0])\n",
    "        elif \"welfare\" in sentence:\n",
    "            welfare.append([sentence, current_years, 0])\n",
    "        elif \"pay gap\" in sentence: #not so sure about check on it\n",
    "            pay_gap.append([sentence, current_years, 0])\n",
    "        elif \"bush\" in sentence:\n",
    "            bush.append([sentence, current_years, 0])\n",
    "        elif \"clinton\" in sentence:\n",
    "            clinton.append([sentence, current_years, 0])\n",
    "        elif \"dole\" in sentence:\n",
    "            dole.append([sentence, current_years, 0])\n",
    "        elif \"affirmative\" in sentence:\n",
    "            affirmative_action.append([sentence, current_years, 0])\n",
    "        elif \"conservative\" in sentence:\n",
    "            conservative.append([sentence, current_years, 0])\n",
    "        elif \"liberal\" in sentence:\n",
    "            liberal.append([sentence, current_years, 0])\n",
    "        elif \"republican\" in sentence:\n",
    "            republican.append([sentence, current_years, 0])\n",
    "        elif \"democrat\" in sentence:\n",
    "            democrat.append([sentence, current_years,0])\n",
    "        elif \"gay\" in sentence:\n",
    "            gay.append([sentence, current_years, 0])\n",
    "\n",
    "for issue in issues:\n",
    "    issue.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing sentences and dates to csv files to data\n",
    "import csv\n",
    "\n",
    "#this is very memory inefficient but it gets it done\n",
    "abortion_backup = open(\"./data/listbackups/abortion.csv\", \"w\", newline=\"\")\n",
    "welfare_backup = open(\"./data/listbackups/welfare.\", \"w\", newline=\"\")\n",
    "pay_gap_backup = open(\"./data/listbackups/pay_gap.csv\", \"w\", newline=\"\")\n",
    "bush_backup = open(\"./data/listbackups/bush.csv\", \"w\", newline=\"\")\n",
    "clinton_backup = open(\"./data/listbackups/clinton.csv\", \"w\", newline=\"\")\n",
    "dole_backup = open(\"./data/listbackups/dole.csv\", \"w\", newline=\"\")\n",
    "affirmative_action_backup = open(\"./data/listbackups/affirmative_action.csv\", \"w\", newline=\"\")\n",
    "conservative_backup = open(\"./data/listbackups/conservative.csv\", \"w\", newline=\"\")\n",
    "liberal_backup = open(\"./data/listbackups/liberal.csv\", \"w\", newline=\"\")\n",
    "republican_backup = open(\"./data/listbackups/republican.csv\", \"w\", newline=\"\")\n",
    "democrat_backup = open(\"./data/listbackups/democrat.csv\", \"w\", newline=\"\")\n",
    "gay_backup = open(\"./data/listbackups/gay.csv\", \"w\", newline=\"\")\n",
    "\n",
    "abortion_writer = csv.writer(abortion_backup)\n",
    "welfare_writer = csv.writer(welfare_backup)\n",
    "pay_gap_writer = csv.writer(pay_gap_backup)\n",
    "bush_writer = csv.writer(bush_backup)\n",
    "clinton_writer = csv.writer(clinton_backup)\n",
    "dole_writer = csv.writer(dole_backup)\n",
    "affirmative_action_writer = csv.writer(affirmative_action_backup)\n",
    "conservative_writer = csv.writer(conservative_backup)\n",
    "liberal_writer = csv.writer(liberal_backup)\n",
    "republican_writer = csv.writer(republican_backup)\n",
    "democrat_writer = csv.writer(democrat_backup)\n",
    "gay_writer = csv.writer(gay_backup)\n",
    "\n",
    "for row in abortion:\n",
    "    abortion_writer.writerow([row[0], row[1]])\n",
    "abortion_backup.close()\n",
    "\n",
    "for row in welfare:\n",
    "    welfare_writer.writerow([row[0], row[1]])\n",
    "welfare_backup.close()\n",
    "\n",
    "for row in pay_gap:\n",
    "    pay_gap_writer.writerow([row[0], row[1]])\n",
    "pay_gap_backup.close()\n",
    "\n",
    "for row in bush:\n",
    "    bush_writer.writerow([row[0], row[1]])\n",
    "bush_backup.close()\n",
    "\n",
    "for row in clinton:\n",
    "    clinton_writer.writerow([row[0], row[1]])\n",
    "clinton_backup.close()\n",
    "\n",
    "for row in dole:\n",
    "    dole_writer.writerow([row[0], row[1]])\n",
    "dole_backup.close()\n",
    "\n",
    "for row in affirmative_action:\n",
    "    affirmative_action_writer.writerow([row[0], row[1]])\n",
    "affirmative_action_backup.close()\n",
    "\n",
    "for row in conservative:\n",
    "    conservative_writer.writerow([row[0], row[1]])\n",
    "conservative_backup.close()\n",
    "\n",
    "for row in liberal:\n",
    "    liberal_writer.writerow([row[0], row[1]])\n",
    "liberal_backup.close()\n",
    "\n",
    "for row in republican:\n",
    "    republican_writer.writerow([row[0], row[1]])\n",
    "republican_backup.close()\n",
    "\n",
    "for row in democrat:\n",
    "    democrat_writer.writerow([row[0], row[1]])\n",
    "democrat_backup.close()\n",
    "\n",
    "for row in gay:\n",
    "    gay_writer.writerow([row[0], row[1]])\n",
    "gay_backup.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6dc828f1700124f558e121b17ff38e71d043bd671fe0cba20393a32585978522"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
